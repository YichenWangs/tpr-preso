<!doctype html>
<html>

<head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

	<title>reveal.js</title>

	<link rel="stylesheet" href="dist/reset.css">
	<link rel="stylesheet" href="dist/reveal.css">
	<link rel="stylesheet" href="dist/theme/blood.css">
	<link rel="stylesheet" href="css/grid.css">
	<link rel="stylesheet" href="plugin/chalkboard/style.css">
	<!-- <link rel="stylesheet" href="plugin/customcontrols/style.css"> -->
	<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css">
	<!-- Theme used for syntax highlighted code -->
	<link rel="stylesheet" href="plugin/highlight/monokai.css">
</head>

<body>
	<div class="reveal">
		<div class="slides">
			<section data-background-video="assets/smc-duo.mov"></section>
			<section data-background-video="assets/cubing-sound.mov"></section>
			<section>
				<div>
					<div class="fragment">
						üë©üèª‚ÄçüíªüßëüèΩ‚Äçüîßüíª
					</div>
					<div class="fragment">
						computer scientists
					</div>
				</div>

				<div class="fragment">
					+
				</div>

				<div>
					<div class="fragment">
						üë®‚Äçüé§üéπüé∏
					</div>
					<div class="fragment">
						musicians
					</div>

				</div>

				<div class="fragment">
					=
				</div>
				<div class="fragment">
					üë®üèº‚Äçüíªüé∂üéºüéµ
				</div>
				<div class="fragment">
					computer musicians
				</div>
				<div class="fragment">
					& üò≠üòÜüòçü§™‚Ä¶
				</div>
			</section>
			<section>
				<section data-background-image="assets/teaser-min.jpg" data-background-repeat="repeat"
					data-background-size="500px" data-background-opacity="0.5">
					<div>
						<h3 style="color:black;background-color: aliceblue; opacity: 0.7;">A story about creating
							musical instrument
							in computers</h3>
					</div>
				</section>
				<section data-background-image="assets/teaser-min.jpg" data-background-repeat="repeat"
					data-background-size="500px" data-background-opacity="0.5">
					<div>
						<h2 style="color:black;background-color: aliceblue; opacity: 0.7;">
							Exploring 3D Musical Gestural
							Control <br> in Augmented Reality </h2>
					</div>
					<div>
						<h4>Yichen Wang</h4>
						<h5>Supervisors: Matt Adcock, Mingze Xi (Data61, CSIRO)
							Charles Martin (ANU)
						</h5>
					</div>
				</section>
			</section>
			<section> NIMEs and CSTs
				<div class="nime-wrap">
					<div>
						<img class="fragment" height="120" alt=""
							src="https://dt7v1i9vyp3mf.cloudfront.net/styles/news_large/s3/imagelibrary/y/yamahatenorion01-EQGcG1Vhq0siZZOyW4LGBZOVeun7JFCx.jpg">
					</div>
					<div>
						<img class="fragment" height="120" alt=""
							src="https://www.clotmag.com/wp-content/uploads/2016/10/1.2.jpg">
					</div>
					<div>
						<img class="fragment" height="120" alt=""
							src="https://blog.bela.io/images/nime2020/svampolin.jpg">
					</div>
					<div>
						<img class="fragment" height="120" alt=""
							src="https://sonami.net/wp-content/uploads/slider2/LS-ladys-glove-05b.jpeg">
					</div>
					<div class="side-right fragment">
						early 2000s
						<br>
						(DIYs & hardware)
					</div>
					<div class="side-left fragment">
						2010s
						<br> (mobile)
					</div>
					<div>
						<img class="fragment" height="120" alt=""
							src="https://microjam.info/images/microjam-outdoor-music-making.jpg">
					</div>
					<div>
						<img class="fragment" height="120" alt=""
							src="https://artful.design/ocarina/images/ocarina2.jpg">
					</div>
					<div>
						<img class="fragment" height="120" alt=""
							src="http://kymatica.com/assets/img/kymatica_studio.png">
					</div>
					<div>
						<img class="fragment" height="120" alt=""
							src="https://britishmusiccollection.org.uk/sites/default/files/styles/header_image_2/public/field/image/95d4a27364fe-IMG_3337.JPG?itok=04tYBLhK">
					</div>
					<div>
						<img class="fragment" height="130" alt=""
							src="https://i1.wp.com/pedrolucas.tech/wp-content/uploads/2019/08/NIME-photo.jpg?ssl=1&resize=1536%2C1536">
					</div>
					<div>
						<img alt="" class="fragment" height="100" src="assets/vr-drum-min.jpg">
					</div>
					<div>
						<img alt="" class="fragment" height="120" src="https://alicelab.world/msvr/images/fig5.png">
					</div>
					<div>
						<img class="fragment" height="120" alt=""
							src="https://i.ytimg.com/vi/ILxpPgkrdi8/maxresdefault.jpg">
					</div>
					<div>
						<img class="fragment" height="120" alt=""
							src="https://cdn.trendhunterstatic.com/thumbs/music-everywhere.jpeg?auto=webp">
					</div>

				</div>
			</section>
			<section>
				<section>
					<p>
						What does Augmented Reality mean in terms of music?
					<p>
				</section>
				<section
					data-background-image="https://cdn.nextgov.com/media/img/cd/2019/12/06/NGpokemon20191206/route-fifty-lead-image.jpg?1627438861">
					<p class="fragment fade-out" id="hlt">
						What does Augmented Reality mean?</p>
				</section>
				<section data-background-image="assets/what-mr.png" data-background-size="1900"
					data-background-opacity="0.5">
					<div id="tbox" class="img-text">
						<div class="item7">
							<ul>
								<li class="fragment">
									the Reality-Virtuality continuum (Milgram & Kishino '94)
								</li>
								<li class="fragment">
									A taxonomy of MR *Displays*: Extend World Knowledge, Reproduction Fidelity, Extend Presence Metaphorc (Milgram et al. '95)
								</li>
								<li class="fragment"> What is Mixed Reality ? (Speicher et al. CHI'19)
									<ul>
										<li class="fragment"> Strong AR - Mixed Reality - HoloLens</li>
										<li class="fragment"> Different applications: MR collaboration (Muller et al.
											CHI'17) & Target selection accuracy in AR headset (Kyto el al. CHI '18)
										</li>
										<li class="fragment"> Dimensions: degree of interaction, level of virtuality,
											level of immersion, number of users and number of environments
										</li>
									</ul>
								</li>


							</ul>
							<img src="assets/kyto-chi.png" alt="" height="200">
						</div>

						<div class="item8">
							<img src="https://www.researchgate.net/publication/29487174/figure/fig1/AS:309967967014938@1450913530882/Milgrams-Reality-Virtuality-Continuum.png"
								width="600" alt="">
							<img src="https://miro.medium.com/max/734/1*8zqDYxybx44vLOrcrIkYQA.jpeg" height="180"
								alt="">
							<img src="assets/muller-chi.png" alt="" height="200">
						</div>

					</div>

				</section>
				<section data-background-image="assets/what-mr.png" data-background-size="1900px"
				data-background-opacity="1">
			</section>
				<section data-background-image="assets/what-mr.png" data-background-size="1900"
					data-background-opacity="0.5">
					<p id="hlt"> It depends! </p>
				</section>
				<section> AR & music ...</section>
				<section>
					<div class="gallery">
						<div class="gallery__item gallery__item--1 fragment">
							<img src="https://www.fing.edu.uy/grupos/medialab/projects/yarmi/images/yarmi1.jpg" alt=""
								class="ig">
						</div>
						<div class="gallery__item gallery__item--2 fragment"><img
								src="https://www.researchgate.net/publication/346668502/figure/fig1/AS:965944776081410@1607310589834/A-user-engaging-with-a-physical-sculpture-through-our-AR-sound-artwork-A-video-can-be.ppm"
								alt="" class="ig">
						</div>
						<div class="gallery__item gallery__item--3 fragment"><img
								src="https://www.fing.edu.uy/grupos/medialab/projects/yarmi/images/yarmi3.png" alt=""
								class="ig">
						</div>
						<div class="gallery__item gallery__item--4 fragment">
							<img src="https://resize-v3.pubpub.org/eyJidWNrZXQiOiJhc3NldHMucHVicHViLm9yZyIsImtleSI6Inp0eWh2Zm40LzExNjExMjk4MzUxMjMyLnBuZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6ODAwLCJmaXQiOiJpbnNpZGUiLCJ3aXRob3V0RW5sYXJnZW1lbnQiOnRydWV9fX0="
								alt="" class="ig">
						</div>
						<div class="gallery__item gallery__item--5 fragment">
							<p class="txt">
								Yarmi (Laurenzo et al. NIME'09) </p>
						</div>
						<div class="gallery__item gallery__item--6 fragment">
							<p class="txt">
								Sonic Sculpture (Martin et al. NIME'20)
								<br>
								Ripples (Wu & Freeman NIME '21)
							</p>
						</div>

					</div>

				</section>

			</section>
			<section data-background-image="https://www.researchgate.net/publication/346668502/figure/fig2/AS:965944776081411@1607310589938/The-HoloLens-augmented-reality-wearable-computer.ppm" data-background-opacity="0.4">
				<h3>Why and what are we interested?</h3>
				<div>
					<div class="img-text">
						<div class="item7">
							<ul class="fragment">
								<li class="fragment">
									New musical interface:
									ultimately a mixed reality instrument playing experience 
									<ul>
										<li class="fragment">
											easy to play ?
										</li>
										<li class="fragment"> 
											accessible ?
										</li>
										<li class="fragment">
											expressive musical control ?
										</li>
										<li class="fragment">
											facilitate new music creation ?
										</li>
									</ul>
								</li>
								<li class="fragment">3D user interface: free hand interaction (6 degree of freedom, fully articulated model and direction manipulation) </li>
								<li class="fragment">Collaboration: access to the reality  </li>
								<li class="fragment">Performer/Researcher/Audience</li>
							</ul>
						</div>


					</div>
				</div>

			</section>
			<section>
				<section>
					New Musical Interface and Expression in Mixed Reality
					<div class="img-text">
						<div class="item6">
							<img width="150" alt=""
								src="https://i1.wp.com/pedrolucas.tech/wp-content/uploads/2019/08/NIME-photo.jpg?ssl=1&resize=1536%2C1536">
							<img width="200" alt="" src="https://alicelab.world/msvr/images/fig5.png">
							<img height="120" alt="" src="https://i.ytimg.com/vi/ILxpPgkrdi8/maxresdefault.jpg">
							<img height="120" alt=""
								src="https://www.fing.edu.uy/grupos/medialab/projects/yarmi/images/yarmi3.png">
							<img src="https://i.ytimg.com/vi/8s1knkVKh0g/maxresdefault.jpg" alt="" height="200">
						</div>
						<div class="item4">
							<h4>What are the issues?</h4>
							<ul class="fragment">
								<li class="fragment">Lack of expressiveness</li>
								<p class="fragment ital">
									RQ1: What factors contribute to the expressiveness of a 3D
										musical
										interface?
									
								</p>


								<li class="fragment">What is an authentic design that benefit musicians for music
									making?</li>
								<p class=" fragment ital">
										RQ2: How can a gestural-sound mapping enhance or affect the experience of
										musicians
										in
										the 3D AR system?
								</p>
								<li class="fragment">How and Where it will be used?
									<p class="fragment ital">
										RQ3: How this interface can be used collaboratively for music ensemble?
									</p>
								</li>

							</ul>
						</div>
					</div>
				</section>

				<section data-background-image="assets/cube-sound-bg.jpg" data-background-size="100%" data-background-repeat="repeat" data-background-opacity="0.3">

					RQ1 Expressive Control

				</section>
				<section>
					<div class="img-text">
						<div class="item4">
							
								<ul>
									<li class="fragment">
										Sound control &#8800 Sound Expression (Dobrian & Koppelman NIME '06)
									</li>
									<li class="fragment">An interface that supports "play"</li>
									<li class="fragment">
										Gestural control of sound synthesis: various data acquisition from input devices including hand, mediated devices, physiological signals, etc (Wanderley & Depalle Proc IEEE '04)
									</li>
									<!-- <img src="https://www.researchgate.net/publication/2986282/figure/fig5/AS:668711174303754@1536444576229/A-symbolic-representation-of-a-DMI.pbm" alt=""> -->

								</ul>


							
						</div>
						<div class="item6">
							<img src="https://i.imgflip.com/6zpmdr.jpg" alt="" width="250">						</div>

					</div>
				</section>

				<section>
					<div class="img-text">
						<div class="fragment item7">
							<ul>
								<li class="fragment">
									When is a Guitar not a Guitar?: a study of interaction modality: plucked strings vs touch sensor (Harrison et a.
									NIME '18)
									<ul>
										<li class="fragment"> Guitarists: "the strings feeling more *natural* to play
											and allowing the use of *existing techniques*
											that they had from the guitar."</li>
										<li class="fragment">
											Non-musicians:
											<ul>
												<li class="fragment"> knows what to do when see the strings</li>
												<li class="fragment"> the sensor: feel confused - what gestures? </li>
												<li class="fragment"> touch screen was more fun </li>
												<li class="fragment"> the strings provided new creativity</li>
											</ul>
										</li>
									</ul>
								</li>
							</ul>
						</div>
						<div class="item8">
							<img src="assets/nime18-guitar.png" alt="" style="float: right; width: 400px">
						</div>
					</div>
				</section>
				<section data-background-image="assets/3d-interaction.png" data-background-size="100%" data-background-opacity="0.5">
					<ul>
						<li class="fragment"> In 3D, exiting musical interactions are mainly navigation, selection & manipulation (Berthaut J. New
							Music Res. '21)
						</li>
						<li class="fragment"> Gestural interaction in MR - the desire for "natural" user interaction, but currently poor affordances :( (Grubert '21) </li>
						<li class="fragment"> But - abrupt design of sound?</li>
					</ul>
				</section>
				<section>
					RQ2 "Authentic" design in terms of musical instrument
				</section>

				<section>
					<div class="img-text">
						<div class="item7">
							<ul>
								<li class="fragment">
									The input-sound mapping in NIME design
									<ul>
										<li class="fragment">
											Turning knobs and patching - synthesisers/electronic
										</li>
										<li class="fragment">
											Finger-string - instruments (e.g. chordophone/guitar)
										</li>
										<li class="fragment"> mixed reality:
											<br>
											Hand gestures - what sound?
										</li>
									</ul>
								<li class="fragment">
									Designer = composer = performer (Morreale et al. NIME '18; Sullivan et al. J. New
									Music Res. '21)
								</li>
								<li class="fragment">
									Design for appropriation (Alan Dix Proc HCI '07; Zappi and Mcpherson NIME '14)
								</li>
								<li class="fragment"> VRMI/MRMI design guideline: (Serafin el al. Comput. Music J.'16;
									Artherton & Wang J. New
									Music Res. '19; Zellerbach &
									Roberts NIME '22)
									<ul>
										<li class="fragment">Design for the body</li>
										<li class="fragment"> Designing to the medium - that is not possible in the
											reality</li>
									</ul>

								</li>



							</ul>

						</div>
						<div class="item8" style="float: right; ">
							<img src="https://www.audiopluginsforfree.com/wp-content/uploads/2016/04/xodular-ecosystem.jpg"
								alt="" height="150">

							<img src="https://alicelab.world/msvr/images/fig5.png" alt="" height="200">

							<img src="assets/nime18-guitar.png" alt="" height="200">

						</div>

					</div>



				</section>
				<section>
					RQ3 The evaluation: how do I and others know this instrument works?
					<div class="fragment"> üëÇüéßüëÅ</div>
				</section>
				<section>
					<ul>
						<li class="fragment"> Different approaches </li>
						<li class="fragment"> Based on different perspectives (O'Modhrain Comput. Music J. '11)
							<ul>
								<li class="fragment"> performer üë©üèº‚Äçüé§ </li>
								<li class="fragment"> audience üë©üèæ‚Äçü¶±üë®üèª‚Äçü¶≥üë©üèª‚Äçü¶∞üßëüèª‚Äçü¶±üë∂üèº
								</li>
								<li class="fragment">developer üë©‚Äçüíª</li>
								<li class="fragment">etc. </li>
							</ul>
						</li>
						<li class="fragment"> First-person approach in HCI (Desjardins et al. TOCHI '21)
						</li>
						<li class="fragment"> Practice-lead: artistic; 
							Rehearsal as research: development-refinement (Martin and Gardner '18) </li>
						<li class="fragment"> Participatory design: what do my users want? </li>
					</ul>
				</section>
			</section>
			<section>
				<section>
					In the last ~12 months: I made an instrument (only that I could see!)
					<div class="r-stack">
						<img src="assets/smc-duo-min.png" class="fragment" alt="">
						<img src="assets/system.jpg" class="fragment fade-in" alt="">
					</div>
				</section>
				<section>
					<img src="assets/tpr.jpg" class="fragment fade-in" alt="">
				</section>
			</section>
			<section>
				<section data-background-image="assets/cubingsound.jpeg" data-background-size="1000px"
					data-background-opacity="0.3">
					<p>
						1. An autobiographical study exploring head-mounted AR musical interfaces:
						<br>
						"what is an authentic design of NIME in Hololens? Does instrument playing work?"

					<p>
				</section>
				<section data-background-video="assets/cubingsound.mp4">
				</section>
				<section data-background-image="assets/cubingsound.jpeg" data-background-size="1000px"
					data-background-opacity="0.2">
					<div class="img-text">
						<div class="item6">
							<ul>
								<li class="fragment"> Controls:
									<ul>
										<li class="fragment">
											knobs and sliders: tuning
										</li>
										<li class="fragment">
											far pointer interaction: less effort, tho similar to using controllers
										</li>
										<li class="fragment">
											hand interaction: using fingers - more varieties
										</li>
									</ul>
								</li>
								<li class="fragment">
									Sound
								</li>
								<li class="fragment">
									More:
									<a href="https://nime.pubpub.org/pub/w82of2do/release/1	"> NIME '22</a>
								</li>
							</ul>
						</div>
						<div class="item8">
							<img src="assets/p1_label.png" width="220" alt="">
							<img src="assets/p2-label.png" width="220" alt="">
							<img src="assets/p3.jpg" width="220" alt="">
						</div>
					</div>

				</section>

			</section>
			<section>

				<section data-background-image="assets/teaser-2-min.jpg" data-background-opacity="0.3">

					2. An expert study with 20 musicians providing in-depth reflections regarding the system in use
				</section>

				<section data-background-video="assets/chi2023.mp4">
				</section>
				<section data-background-image="assets/merged-stats.jpg" data-background-opacity="0.3">
					<ul>
						<li class="fragment fade-in-then-out"> Musical tasks:
							more structured to test various aspects of the instrument
						</li>
						<li class="fragment fade-in-then-out"> Questionnaire + semi-structured interview

						</li>
						<li class="fragment fade-in-then-out">
							Functionality,learnability, explorability and enjoyment
						</li>
						<li class="fragment fade-in-then-out
							">
							How was your overall experience? What impressed you in terms of interaction, sound and visuals?
						</li>

						<li class="fragment">
							High explorability and learnability
						</li>
						<li class="fragment"> Enjoyment varies </li>
						<li class="fragment">
							Less good functionality
						</li>


						<li class="fragment">ANU human ethics research protocol: 2022/413</li>
					</ul>
				</section>
				<section data-background-image="assets/initial-ta-m.jpg" data-background-position="center"
					data-background-size="150%">

				</section>
				<section data-background-image="assets/reflexive-ta.jpg" data-background-size="88%">
				</section>
				<section data-background-image="assets/reflexive-ta.jpg" data-background-size="88%"
					data-background-opacity="0.3">
					<div>
						<ul>
							<li class="fragment"> Reflexive thematic analysis:
								collating important codes and themes 
							</li>
							<li class="fragment">
								Gestures in space and usability
								<ul>
									<li class="fragment">
										hand tracking & explorability
									</li>
									<li class="fragment"> accessible</li>
								</ul>
							</li>
							<li class="fragment">Performer's identity:
								enjoyment
							</li>
							<li class="fragment">
								Embodiment, new musical experience, etc
							</li>
						</ul>
					</div>

				</section>

			</section>

			<section data-background-image="assets/tpr.jpg" data-background-size="100%" data-background-opacity="0.1">
				<div class="img-text">
					<div class="item7">
							<h3>Summary</h3>
							<ul>
								<li class="fragment"> An authentic design of new musical interface in MR headset
								</li>
								<li class="fragment">
									Formal user studies: various interaction possibilities using hand gestures and issues
								</li>
								<li class="fragment"> 
									Performing with others in gig to keep experimenting and exploring 
								</li>
							</ul>

							<h3 class="fragment"> Now and onwards</h3>

							<ul>
								<li class="fragment"> Upcoming performance at OZCHI2022</li>
								<li class="fragment"> Improve the hand tracking issue</li>
								<li class="fragment"> Specifically looking into gesture analysis</li>
								<li class="fragment"> Longitudinal study</li>
							</ul>
						
					</div>
					<div class="item8">
						<img src="assets/yichen-oslo-min.JPG" alt="">
						<div class="tweet" data-src="https://twitter.com/benswift/status/1588291501297000449?s=20&t=DrfidQEBb49LIxTaXmBvdg"></div>

					</div>
				</div>

			</section>
			<section>
				<h3> Reference</h3>
				<div style="font-size: medium;">
				<ul>
					<li> Iwai, T., & Nishibori, Y. (2005, August). Tenori-on. In SIGGRAPH 2005.</li>
					<li> Jord√†, S., Kaltenbrunner, M., Geiger, G., & Alonso, M. (2006). The reacTable: a tangible tabletop musical instrument and collaborative workbench. In ACM SIGGRAPH 2006 Sketches (pp. 91-es).</li>
					<li> Pardue, L. S., Buys, K., Edinger, M., Overholt, D., & McPherson, A. (2019, March). Separating sound from source: sonic transformation of the violin through electrodynamic pickups and acoustic actuation. In NIME 2019 New Interfaces for Musical Expression conference (pp. 278-283).</li>
					<li> lady's glove - LAETITIA SONAMI</li>
					<li> Martin, C. P., & T√∏rresen, J. (2017). MicroJam: an app for sharing tiny touch-screen performances. In Proceedings of the International Conference on New Interfaces for Musical Expression (pp. 495-496). Aalborg University Copenhagen.</li>
					<li> Wang, G. (2009, June). Designing smule‚Äôs iphone ocarina. In Proceedings of the International Conference on New Interfaces for Musical Expression. Pittsburgh (Vol. 291).</li>
					<li> http://kymatica.com</li>
					<li> McLean, A., & Wiggins, G. (2010). Tidal‚Äìpattern language for the live coding of music. In Proceedings of the 7th sound and music computing conference (pp. 331-334).</li>
					<li> Lucas, P. P., Queiroz, M., & Sed√≥, A. X. (2019). AuSynthAR: A simple low-cost modular synthesizer based on Augmented Reality. In NIME (pp. 405-406).</li>
					<li> Schlagowski, R., Wildgrube, F., Mertes, S., George, C., & Andr√©, E. (2022, June). Flow with the Beat! Human-Centered Design of Virtual Environments for Musical Creativity Support in VR. In Creativity and Cognition (pp. 428-442). </li>
					<li> Wakefield, G., Palumbo, M., & Zonta, A. (2020, July). Affordances and Constraints of Modular Synthesis in Virtual Reality. In Proceedings of the International Conference on New Interfaces for Musical Expression (pp. 547-550). </li>
					<li> Hamilton, R. (2019, March). Coretet: A Dynamic Virtual Musical Instrument for the Twenty-First Century. In 2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR) (pp. 1395-1395). IEEE.</li>
					<li> Charles Martin 2020</li>
					<li> Twilight (2013), Stanford Laptop Orchestra </li>
					<li> Pure Data</li>
					<li> Qianchao Lan 2022</li>
				</ul>
			</div>
			</section>
			<!-- <section>
				<section>
					<h3>Now and onwards</h3>
					<div class="tsize"> -->
						<!-- <div class="tweet" data-src="https://twitter.com/benswift/status/1588291501297000449?s=20&t=DrfidQEBb49LIxTaXmBvdg"></div> -->
					<!-- </div>
				</section>
		</section> -->
	</div>
	</div>

	<script src="dist/reveal.js"></script>
	<script src="plugin/notes/notes.js"></script>
	<script src="plugin/markdown/markdown.js"></script>
	<script src="plugin/highlight/highlight.js"></script>
	<script src="plugin/chalkboard/plugin.js"></script>
	<!-- <script src="plugin/embed-tweet/plugin.js"></script> -->
	<!-- <script src="plugin/customcontrols/plugin.js"></script> -->
	<script>
		// More info about initialization & config:
		// - https://revealjs.com/initialization/
		// - https://revealjs.com/config/
		Reveal.initialize({
			hash: true,
			// disableLayout: false,
			//autoPlayMedia: true,
			chalkboard: { 
				// optionally load pre-recorded chalkboard drawing from file
				src: "chalkboard.json",
			},
			dependencies: [
				// ... 
				{ src: 'plugin/chalkboard/chalkboard.js' },
				// ... 
			],
			keyboard: {
				67: function() { RevealChalkboard.toggleNotesCanvas() },	// toggle notes canvas when 'c' is pressed
				66: function() { RevealChalkboard.toggleChalkboard() },	// toggle chalkboard when 'b' is pressed
				46: function() { RevealChalkboard.clear() },	// clear chalkboard when 'DEL' is pressed
				8: function() { RevealChalkboard.reset() },	// reset chalkboard data on current slide when 'BACKSPACE' is pressed
				68: function() { RevealChalkboard.download() },	// downloccccad recorded chalkboard drawing when 'd' is pressed
			},
			// Learn about plugins: https://revealjs.com/plugins/
			plugins: [RevealMarkdown, RevealHighlight, RevealNotes, RevealChalkboard ]
		});
	</script>
</body>

</html>